{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjNwQyZv52wg/LRVVAUvsO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eunsinchoi/prectice01/blob/main/%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98_%EB%B9%A0%EB%A5%B8_%EC%8B%9C%EC%9E%91.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Fg95Ii9wfhUU"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision import datasets"
      ],
      "metadata": {
        "id": "el7Ncfd0gSMe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = datasets.FashionMNIST(\n",
        "    root='data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root='data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "id": "2mx9NqZRglrG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee7bbd15-45ae-4728-d8bf-e7c41b376204"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 19161132.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 334554.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 6168613.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 15970619.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader :\n",
        "  print(f\"Shape of X [N, C, H, w] : {X.shape}\")\n",
        "  print(f\"Shape of y : {y.shape} {y.dtype}\")\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8EhcqzjhfOw",
        "outputId": "306dce9a-7c16-4310-f8cb-d46ae1410d6d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, w] : torch.Size([64, 1, 28, 28])\n",
            "Shape of y : torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6LYE9ahi0zI",
        "outputId": "086a0beb-d4fd-4b91-b946-b73ec2402917"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module) :\n",
        "  def __init__(self) :\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,18)\n",
        "    )\n",
        "\n",
        "  def forward(self, x) :\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "U3fUfozC8HLY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tAdgshO9lvC",
        "outputId": "4d43c317-1c30-42e5-e2ef-84c3b2bdc5af"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=18, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 매개변수 최적화하기\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "NbHEsobF9v5a"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    #예측오류계산\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    #역전파\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 100 == 0 :\n",
        "      loss, current = loss.item(), (batch+1)*len(X)\n",
        "      print(f\"loss : {loss:>7f} [{current:>5d}/{size:>5d}]\")\n"
      ],
      "metadata": {
        "id": "gkBBRgsE-anL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "      test_loss /= num_batches\n",
        "      correct /= size\n",
        "      print(f\"Test Error : \\n Accuray : {(100*correct):>0.1f}%, Avg loss : {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "v2wwRfE-I0_7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n----------------------------------\")\n",
        "  train(train_dataloader, model, loss_fn, optimizer)\n",
        "  test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "dqTwn8ZfLAzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae97645c-9a9d-4292-93b6-7034e1406620"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "----------------------------------\n",
            "loss : 2.887555 [   64/60000]\n",
            "loss : 2.845472 [ 6464/60000]\n",
            "loss : 2.789972 [12864/60000]\n",
            "loss : 2.758964 [19264/60000]\n",
            "loss : 2.681506 [25664/60000]\n",
            "loss : 2.606761 [32064/60000]\n",
            "loss : 2.598839 [38464/60000]\n",
            "loss : 2.498896 [44864/60000]\n",
            "loss : 2.431158 [51264/60000]\n",
            "loss : 2.363916 [57664/60000]\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014924 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014756 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014594 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014877 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014859 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.014670 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014624 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014688 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014959 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014916 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014639 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.015101 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.014763 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.015171 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014998 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.014988 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014954 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015193 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.015031 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014716 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014746 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014640 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015095 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.015280 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.015215 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015109 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014736 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.015229 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015146 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014645 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.014992 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014840 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014864 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014834 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015497 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.014683 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014935 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.014930 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.014546 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.015156 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014781 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014605 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015052 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014654 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.015066 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014876 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015048 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.015079 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015280 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.015136 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015198 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014605 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015142 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015342 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015008 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.015206 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014732 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015192 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014736 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.014680 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015364 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.014892 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014752 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014780 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014700 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.014813 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.014894 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014665 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015238 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014644 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.014705 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014699 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014912 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.015082 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014880 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014833 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.014585 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014926 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014896 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015353 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014556 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.015183 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014895 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014993 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.014817 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014855 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015036 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.015121 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.014758 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014813 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014977 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015005 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014936 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014715 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015088 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015145 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014798 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.014793 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.015061 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.015491 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014956 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014921 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014563 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015039 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015298 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015014 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015043 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.015302 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.015078 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015218 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.014862 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014608 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.015217 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014869 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014589 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014737 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015100 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014905 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015037 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.015118 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.015105 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.015431 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.014934 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015282 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014761 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014965 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.014696 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015526 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015199 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.014887 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015085 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014844 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014753 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014692 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.015212 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014840 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014786 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015161 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014743 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.014920 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014690 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014690 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.015111 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.014950 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015128 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014675 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014912 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015241 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.014988 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014771 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.015031 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014899 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014637 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015142 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.015208 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.014621 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.015530 \n",
            "\n",
            "Epoch 2\n",
            "----------------------------------\n",
            "loss : 2.352135 [   64/60000]\n",
            "loss : 2.322763 [ 6464/60000]\n",
            "loss : 2.197938 [12864/60000]\n",
            "loss : 2.221228 [19264/60000]\n",
            "loss : 2.124418 [25664/60000]\n",
            "loss : 2.016665 [32064/60000]\n",
            "loss : 2.070085 [38464/60000]\n",
            "loss : 1.946886 [44864/60000]\n",
            "loss : 1.948716 [51264/60000]\n",
            "loss : 1.838401 [57664/60000]\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011740 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011483 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011179 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011660 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011857 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011376 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011621 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011534 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011805 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.012004 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011901 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011924 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011326 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011428 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.012050 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012159 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011864 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012340 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011917 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011833 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011874 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011638 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011800 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012001 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012078 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011932 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011559 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012286 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012081 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.010790 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011892 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011397 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011674 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011416 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.012205 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011549 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011695 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011814 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011514 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011801 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011656 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011742 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012005 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011432 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012138 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011990 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011863 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.012037 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012263 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012118 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.2%, Avg loss : 0.012333 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011616 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011895 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012347 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012087 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011906 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011648 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012071 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011717 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011556 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012258 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011943 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011646 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011740 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011900 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011709 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011859 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.011338 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.012004 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011295 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.011176 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.011355 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011713 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012015 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011924 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011539 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011322 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011775 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011971 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012394 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011712 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.012124 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011797 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011639 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011416 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011851 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011751 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012260 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011704 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011602 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011802 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011724 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011387 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011686 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011624 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011745 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011332 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011806 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012172 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012190 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011918 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011836 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011386 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012156 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012215 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011555 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012002 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012157 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012098 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011834 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011694 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011155 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012200 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011794 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011434 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011682 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011931 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011429 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011995 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011854 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011931 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012362 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011751 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012105 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011825 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011819 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011405 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012684 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.012194 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011939 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011729 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.011295 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011354 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011594 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012022 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011384 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011740 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011662 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011353 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011662 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011093 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011579 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011974 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011993 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012318 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011594 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011733 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011832 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011602 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011704 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.011903 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011659 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011522 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011698 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.012136 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.011439 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.012090 \n",
            "\n",
            "Epoch 3\n",
            "----------------------------------\n",
            "loss : 1.899599 [   64/60000]\n",
            "loss : 1.856390 [ 6464/60000]\n",
            "loss : 1.698483 [12864/60000]\n",
            "loss : 1.743368 [19264/60000]\n",
            "loss : 1.615145 [25664/60000]\n",
            "loss : 1.577880 [32064/60000]\n",
            "loss : 1.592405 [38464/60000]\n",
            "loss : 1.496798 [44864/60000]\n",
            "loss : 1.518290 [51264/60000]\n",
            "loss : 1.405719 [57664/60000]\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009064 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.008697 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008577 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009019 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009336 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008688 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009072 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009007 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009185 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009703 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009641 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009337 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008501 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008487 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009388 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.009813 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.009270 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.009883 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.009386 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009529 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009357 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009149 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008966 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009280 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009346 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009279 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009050 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009751 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.009639 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.007773 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.009332 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008654 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009134 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.008579 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009419 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.008989 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008972 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009154 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009073 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009088 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009107 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009436 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009549 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008772 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009720 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.009805 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009138 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009722 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.009678 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009395 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.010006 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009263 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009164 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.009776 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.009735 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009082 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009203 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.009579 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009136 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009227 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.009591 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009668 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009237 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009220 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.009601 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009153 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009288 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.008651 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009322 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.008572 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.008288 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.008526 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009068 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.009435 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009274 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008922 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008811 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009066 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.009639 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009889 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009453 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009310 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009263 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.008810 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008726 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009310 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009111 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.009969 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009138 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008948 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009257 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008854 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008405 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009375 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008906 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008967 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008596 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.009315 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.009908 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009352 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009437 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009190 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008807 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009582 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.009793 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.008768 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.009516 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009499 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009519 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009072 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009093 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.008476 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.009650 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009160 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008811 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009171 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009218 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008754 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009472 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009234 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009166 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009535 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009128 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009683 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.009409 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009219 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008789 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.010173 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009609 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.009394 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008992 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.008366 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008598 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008962 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009397 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.008619 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.009469 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.008690 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.008627 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009072 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008255 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009107 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009458 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.009608 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009787 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009086 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009104 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008962 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009014 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009243 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009459 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.009019 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008873 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008874 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.009617 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008952 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.009218 \n",
            "\n",
            "Epoch 4\n",
            "----------------------------------\n",
            "loss : 1.517604 [   64/60000]\n",
            "loss : 1.487512 [ 6464/60000]\n",
            "loss : 1.321963 [12864/60000]\n",
            "loss : 1.405283 [19264/60000]\n",
            "loss : 1.278096 [25664/60000]\n",
            "loss : 1.288493 [32064/60000]\n",
            "loss : 1.301890 [38464/60000]\n",
            "loss : 1.231746 [44864/60000]\n",
            "loss : 1.269524 [51264/60000]\n",
            "loss : 1.170496 [57664/60000]\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007544 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007017 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.007192 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007477 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007792 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007140 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007511 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007494 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007619 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008371 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008219 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007845 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006967 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006918 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007743 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.008468 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007799 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008450 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007990 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008144 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007872 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007727 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007305 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007728 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007641 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007738 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007645 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008235 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.008327 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.6%, Avg loss : 0.006036 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007837 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007156 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007725 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006976 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007817 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.007466 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007272 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007537 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007621 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007560 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007719 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008104 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008182 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.007207 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008249 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.008667 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007501 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008480 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008191 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007696 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.008773 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007875 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007529 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008318 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008450 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007461 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007862 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008216 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007514 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007936 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.008058 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008441 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007854 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007868 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.008207 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007610 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.007772 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.007001 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007847 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006929 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006599 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006874 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.007478 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.007954 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007669 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007499 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007413 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007399 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.008425 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008375 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008167 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007631 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007788 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.007194 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007221 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007888 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007639 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.008668 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007660 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007430 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007812 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007158 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006703 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008123 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007324 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007471 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007062 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007851 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008584 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007717 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008019 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007612 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007314 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007982 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.008486 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.007127 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.008035 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007954 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.008059 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007578 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007490 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006944 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.008228 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007566 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.007257 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007732 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007603 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007263 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008010 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007721 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007623 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007864 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007588 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008502 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008011 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007694 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007269 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008669 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008136 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.007930 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007417 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006636 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.007036 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007428 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007874 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.007035 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.008262 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.007043 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007110 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007611 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006655 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007711 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008035 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008140 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008206 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007666 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007619 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.007262 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007617 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007952 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.008174 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007432 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.007294 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007290 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.008269 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007486 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.007504 \n",
            "\n",
            "Epoch 5\n",
            "----------------------------------\n",
            "loss : 1.284343 [   64/60000]\n",
            "loss : 1.271048 [ 6464/60000]\n",
            "loss : 1.096484 [12864/60000]\n",
            "loss : 1.212755 [19264/60000]\n",
            "loss : 1.079580 [25664/60000]\n",
            "loss : 1.109803 [32064/60000]\n",
            "loss : 1.133973 [38464/60000]\n",
            "loss : 1.073485 [44864/60000]\n",
            "loss : 1.117481 [51264/60000]\n",
            "loss : 1.029923 [57664/60000]\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006642 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005957 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006357 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006512 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006780 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006177 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006529 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006533 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006640 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007548 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007265 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006937 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006049 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005979 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006661 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.007638 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006889 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007571 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007136 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007277 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006996 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006842 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006266 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006770 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006503 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006772 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006768 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007281 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007523 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.6%, Avg loss : 0.004943 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006919 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006271 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006847 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005987 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006803 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006501 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006180 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006506 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006671 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006622 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006890 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007293 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007371 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006202 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007297 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.008048 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006486 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007717 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007274 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006626 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.008081 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006970 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006489 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007418 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007694 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006490 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007044 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.007384 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006455 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.007133 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.007123 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007743 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006972 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007098 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.007349 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006645 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006843 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005911 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006937 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005869 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005538 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005835 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006463 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.007043 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006646 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006674 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006541 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006342 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.007718 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007411 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007374 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006597 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006842 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006209 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006280 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007051 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006766 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.007872 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006780 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006525 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006889 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006102 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005625 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007365 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006311 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006602 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006087 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006918 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007755 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006707 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007129 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006636 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006394 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006953 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007718 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006059 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.007103 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006995 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.007210 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006702 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006457 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005968 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007384 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006562 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006310 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006847 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006585 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006317 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007091 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006767 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006718 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006822 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006628 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007827 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007189 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006753 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006304 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007688 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007259 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.007050 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006418 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005575 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006086 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006497 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006924 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006053 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007552 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006054 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006207 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006703 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005696 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006884 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007144 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007202 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007208 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006806 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006710 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006203 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006790 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007227 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007444 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006410 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006311 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006330 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007490 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006556 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.006361 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZVUXaRYLh1R",
        "outputId": "18edb625-dd1d-4d27-94aa-5982fceefa67"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_nw6-LtNXi1",
        "outputId": "8f769503-42bd-452e-b4b4-ea5d91d90f60"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    x = x.to(device)\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_w8kaiWNkzb",
        "outputId": "86259086-b619-4ed2-a157-2473efa59d2f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VJ_-Upd3NpF9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}