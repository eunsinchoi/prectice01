{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOHasTACbWk4e/dGjs23zyM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eunsinchoi/prectice01/blob/main/%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98_%EB%B9%A0%EB%A5%B8_%EC%8B%9C%EC%9E%91.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Fg95Ii9wfhUU"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision import datasets"
      ],
      "metadata": {
        "id": "el7Ncfd0gSMe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = datasets.FashionMNIST(\n",
        "    root='data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root='data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "id": "2mx9NqZRglrG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfd96f10-4ca8-4857-c351-cd5a3f26e84e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:02<00:00, 10590483.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 201306.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 3717583.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 5731955.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader :\n",
        "  print(f\"Shape of X [N, C, H, w] : {X.shape}\")\n",
        "  print(f\"Shape of y : {y.shape} {y.dtype}\")\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8EhcqzjhfOw",
        "outputId": "bf7301ee-76c2-44a5-e790-e3e8d56cb042"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, w] : torch.Size([64, 1, 28, 28])\n",
            "Shape of y : torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6LYE9ahi0zI",
        "outputId": "f81643f7-35d7-4e04-88fc-62d748f6e766"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module) :\n",
        "  def __init__(self) :\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,18)\n",
        "    )\n",
        "\n",
        "  def forward(self, x) :\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "U3fUfozC8HLY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tAdgshO9lvC",
        "outputId": "182c0eb9-5601-4466-c5a2-d7adfa5ad089"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=18, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 매개변수 최적화하기\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "NbHEsobF9v5a"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    #예측오류계산\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    #역전파\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 100 == 0 :\n",
        "      loss, current = loss.item(), (batch+1)*len(X)\n",
        "      print(f\"loss : {loss:>7f} [{current:>5d}/{size:>5d}]\")\n"
      ],
      "metadata": {
        "id": "gkBBRgsE-anL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches = len(dataloader)\n",
        "  model.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "      test_loss /= num_batches\n",
        "      correct /= size\n",
        "      print(f\"Test Error : \\n Accuray : {(100*correct):>0.1f}%, Avg loss : {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "v2wwRfE-I0_7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n----------------------------------\")\n",
        "  train(train_dataloader, model, loss_fn, optimizer)\n",
        "  test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "dqTwn8ZfLAzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "605d2180-9fec-4213-f2a3-424b180a3bfe"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "----------------------------------\n",
            "loss : 1.133400 [   64/60000]\n",
            "loss : 1.127976 [ 6464/60000]\n",
            "loss : 0.943043 [12864/60000]\n",
            "loss : 1.084277 [19264/60000]\n",
            "loss : 0.951439 [25664/60000]\n",
            "loss : 0.982794 [32064/60000]\n",
            "loss : 1.034129 [38464/60000]\n",
            "loss : 0.975323 [44864/60000]\n",
            "loss : 1.011765 [51264/60000]\n",
            "loss : 0.942788 [57664/60000]\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006065 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005206 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005776 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005861 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006008 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005508 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005871 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005904 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006021 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006980 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006533 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006391 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005436 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005340 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005950 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006985 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006218 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006964 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006579 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006708 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006352 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006205 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005509 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006015 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005660 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006151 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006089 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006608 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006919 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.6%, Avg loss : 0.004284 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006377 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005705 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006168 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005320 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006027 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005858 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005438 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005823 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005914 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005917 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006315 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006724 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006805 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005509 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006680 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.007619 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005851 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007184 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006603 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005882 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.007589 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006429 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005771 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006815 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007121 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005910 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006514 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006818 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005849 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006595 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006416 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007303 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006287 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006532 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006731 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005966 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006309 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005202 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006264 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005129 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004855 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005139 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005805 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006399 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005932 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006175 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005970 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005614 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007261 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006687 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006897 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005905 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006085 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005567 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005595 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006469 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006220 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.007309 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006185 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005919 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006232 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005553 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004898 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006813 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005574 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006045 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005469 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006238 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007127 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005973 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006482 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005972 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005859 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006218 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007236 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005223 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006459 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006389 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006568 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006166 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005792 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005212 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006813 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005930 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005626 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006193 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005879 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005653 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006475 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006060 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006031 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006126 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006015 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007335 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006600 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006145 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005625 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006995 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006572 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006509 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005611 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004887 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005530 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005921 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006275 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005439 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007115 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005453 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005639 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006155 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005133 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006314 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006530 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006555 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006402 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006148 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006011 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005519 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006267 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006774 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006907 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005675 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005721 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005607 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006949 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005925 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.005689 \n",
            "\n",
            "Epoch 2\n",
            "----------------------------------\n",
            "loss : 1.019009 [   64/60000]\n",
            "loss : 1.035985 [ 6464/60000]\n",
            "loss : 0.834682 [12864/60000]\n",
            "loss : 0.997892 [19264/60000]\n",
            "loss : 0.868473 [25664/60000]\n",
            "loss : 0.893736 [32064/60000]\n",
            "loss : 0.963119 [38464/60000]\n",
            "loss : 0.906470 [44864/60000]\n",
            "loss : 0.935725 [51264/60000]\n",
            "loss : 0.878315 [57664/60000]\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005683 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004706 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005328 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005403 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005483 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005029 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005361 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005465 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005559 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006582 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006013 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005985 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005027 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004881 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005414 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006592 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005742 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006527 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006160 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006270 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005958 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005744 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005021 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005536 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005087 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005685 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005638 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006134 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006520 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.6%, Avg loss : 0.003778 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005952 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005340 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005729 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004859 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005531 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005376 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004946 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005329 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005421 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005473 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005920 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006324 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006384 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004977 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006199 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.007343 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005397 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006769 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006161 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005397 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.007324 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005976 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005290 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006352 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006763 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005525 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006111 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006412 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005334 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006197 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005958 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006970 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005837 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006208 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006326 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005489 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005919 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004657 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005789 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004602 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004372 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004609 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005317 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005977 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005419 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005827 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005555 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005115 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006916 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006231 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006509 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005411 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005591 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005179 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005161 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006083 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005875 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006880 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005793 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005562 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005782 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005097 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004377 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006426 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005080 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005678 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004995 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005735 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006701 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005491 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006011 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005490 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005427 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005715 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006917 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004683 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006027 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005918 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006166 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005769 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005312 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004715 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006395 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005450 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005210 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005752 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005388 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005202 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006036 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005592 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005598 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005616 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005578 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006999 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006214 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005737 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005166 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006493 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006132 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006095 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005093 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004447 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005101 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005496 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005817 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004949 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006787 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005007 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005261 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005765 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004720 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005929 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006083 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006115 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005919 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005752 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005576 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005045 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005908 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006421 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006581 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005181 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005260 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005159 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006576 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005529 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.005052 \n",
            "\n",
            "Epoch 3\n",
            "----------------------------------\n",
            "loss : 0.933126 [   64/60000]\n",
            "loss : 0.970162 [ 6464/60000]\n",
            "loss : 0.755903 [12864/60000]\n",
            "loss : 0.936464 [19264/60000]\n",
            "loss : 0.812349 [25664/60000]\n",
            "loss : 0.828733 [32064/60000]\n",
            "loss : 0.912532 [38464/60000]\n",
            "loss : 0.860179 [44864/60000]\n",
            "loss : 0.880423 [51264/60000]\n",
            "loss : 0.831691 [57664/60000]\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005435 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004347 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004982 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005076 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005094 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004675 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.004977 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005170 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005223 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006288 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005632 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005694 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004746 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004530 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005034 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006321 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005379 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006197 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005847 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005945 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005671 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005405 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004668 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005181 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004677 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005340 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005296 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005780 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006230 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.6%, Avg loss : 0.003424 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005650 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005105 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005410 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004533 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005161 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005007 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004603 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004974 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005065 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005153 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005628 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006031 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006051 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004585 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005840 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.007143 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005091 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006430 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005847 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005062 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.007152 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005657 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004953 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005998 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006503 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005274 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005804 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006112 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.004967 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005901 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005619 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006712 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005513 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005988 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006039 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005137 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005655 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004269 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005419 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004215 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004035 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004214 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004968 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005670 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005049 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005588 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005255 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004768 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006643 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005903 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006228 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005057 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005230 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004933 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.004846 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005807 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005661 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006560 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005514 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005336 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005462 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004785 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.003996 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006127 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004714 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005424 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004657 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005350 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006380 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005132 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005664 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005141 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005123 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005354 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006704 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004291 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005727 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005571 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005860 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005484 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004971 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004352 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006078 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005114 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004925 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005417 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005037 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004869 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005720 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005252 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005270 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005237 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005267 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006724 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005935 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005454 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004837 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006122 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005793 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005797 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004706 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004153 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004791 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005205 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005480 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004584 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006548 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004696 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.004999 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005500 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004431 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005643 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005752 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005805 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005571 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005466 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005256 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004714 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005652 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006147 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006324 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004824 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004915 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004828 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006284 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005267 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.004554 \n",
            "\n",
            "Epoch 4\n",
            "----------------------------------\n",
            "loss : 0.866835 [   64/60000]\n",
            "loss : 0.920030 [ 6464/60000]\n",
            "loss : 0.696914 [12864/60000]\n",
            "loss : 0.891073 [19264/60000]\n",
            "loss : 0.772219 [25664/60000]\n",
            "loss : 0.780596 [32064/60000]\n",
            "loss : 0.873841 [38464/60000]\n",
            "loss : 0.827462 [44864/60000]\n",
            "loss : 0.838903 [51264/60000]\n",
            "loss : 0.796255 [57664/60000]\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005266 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004078 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004707 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004835 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004795 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004403 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.004677 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.004963 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004964 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006060 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005348 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005472 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004543 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004245 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004754 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006128 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005087 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005932 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005603 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005696 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005448 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005147 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004398 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004907 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004377 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005074 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005020 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005503 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006007 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.6%, Avg loss : 0.003169 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005425 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004948 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005168 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004294 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004870 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004714 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004353 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004708 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004803 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004911 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005400 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005805 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005776 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004292 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005564 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.006987 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004878 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006142 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005613 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.004819 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.007027 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005428 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004705 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005712 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006304 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005099 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005555 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005878 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.004699 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005672 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005357 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006501 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005270 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005829 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005828 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004864 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005466 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.003983 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005121 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.6%, Avg loss : 0.003919 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.003789 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.003911 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004713 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005431 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004771 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005417 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005027 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004517 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006416 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005661 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006017 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004791 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004959 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004768 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004606 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005602 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005527 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006315 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005310 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005187 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005225 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.004561 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.003706 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005884 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004432 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005238 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004409 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005050 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006128 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.004854 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005402 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004880 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004902 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005084 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006555 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.003997 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005506 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005306 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005611 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005265 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004719 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004077 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005826 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004868 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004723 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005149 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004773 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004612 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005485 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004996 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005007 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004942 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005035 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006480 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005726 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005252 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004592 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005836 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005520 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005572 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004404 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.003946 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004552 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.004998 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005221 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004303 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006363 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004468 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004804 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005309 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004217 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005414 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005498 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005577 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005313 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005244 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005011 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004469 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005456 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005919 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006104 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004555 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004641 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004570 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006040 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005092 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.004151 \n",
            "\n",
            "Epoch 5\n",
            "----------------------------------\n",
            "loss : 0.814179 [   64/60000]\n",
            "loss : 0.879553 [ 6464/60000]\n",
            "loss : 0.651192 [12864/60000]\n",
            "loss : 0.856278 [19264/60000]\n",
            "loss : 0.741813 [25664/60000]\n",
            "loss : 0.744261 [32064/60000]\n",
            "loss : 0.842084 [38464/60000]\n",
            "loss : 0.802921 [44864/60000]\n",
            "loss : 0.806439 [51264/60000]\n",
            "loss : 0.767892 [57664/60000]\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005142 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.003865 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004483 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004651 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004557 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004187 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.004434 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.004807 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004756 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005876 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005132 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005295 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004384 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004002 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004542 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005983 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004844 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005710 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005403 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005499 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005260 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004942 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004181 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004687 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004146 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004856 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004790 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005277 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005826 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.6%, Avg loss : 0.002980 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005250 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004838 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.004976 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004114 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004631 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004472 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004162 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004502 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004600 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004722 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005212 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005625 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005540 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004066 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005343 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.3%, Avg loss : 0.006857 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004721 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005889 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005429 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.004635 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006926 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005257 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004511 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005471 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006144 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004965 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005340 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005687 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.004496 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005488 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005143 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006318 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005079 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005706 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005668 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004644 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005319 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.003763 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004873 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.6%, Avg loss : 0.003683 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.003603 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.003670 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004519 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005234 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004554 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005288 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004846 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004326 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006221 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005474 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005849 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004583 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004749 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004648 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004415 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005444 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005441 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006120 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005154 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005081 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005043 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004390 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.003477 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005679 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004207 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005091 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004222 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.004809 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005922 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004630 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005197 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004680 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004738 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.004874 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006441 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.003772 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005336 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005094 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005395 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005087 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004525 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.003861 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005618 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004679 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004573 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004923 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004565 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004406 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005299 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004793 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004787 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004702 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004853 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.006257 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005559 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005101 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004404 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005606 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005291 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005392 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004158 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.003789 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004356 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.004841 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005010 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004078 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.006215 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004294 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004648 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005165 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004050 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005219 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005296 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005401 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005114 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005061 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004813 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004275 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005297 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005718 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.005902 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004344 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004415 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004357 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.4%, Avg loss : 0.005826 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.5%, Avg loss : 0.004970 \n",
            "\n",
            "Test Error : \n",
            " Accuray : 0.1%, Avg loss : 0.003817 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZVUXaRYLh1R",
        "outputId": "c34b9658-caef-46c2-8f21-f733757f0e9a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_nw6-LtNXi1",
        "outputId": "94952d41-62a1-4460-b219-b4cc03482fae"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    x = x.to(device)\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_w8kaiWNkzb",
        "outputId": "f9392284-7132-40e1-bf2f-d4e3a28fb060"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    }
  ]
}